{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmv-2dIdgJ8O"
      },
      "source": [
        "# Sentiment Analysis on IMDB Reviews using Ensemble Model. (LTSM, CNN, GRU)\n",
        "<hr>\n",
        "\n",
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:15.861275Z",
          "iopub.status.busy": "2026-01-06T18:37:15.860412Z",
          "iopub.status.idle": "2026-01-06T18:37:15.867638Z",
          "shell.execute_reply": "2026-01-06T18:37:15.866499Z",
          "shell.execute_reply.started": "2026-01-06T18:37:15.861237Z"
        },
        "id": "dgMzzmV5gJ8S",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential, Model     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Conv1D, GlobalMaxPooling1D, GRU, Dense, Dropout, Input, Average # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhdUHDxcgJ8U"
      },
      "source": [
        "\n",
        "### Preview dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:15.870686Z",
          "iopub.status.busy": "2026-01-06T18:37:15.869747Z",
          "iopub.status.idle": "2026-01-06T18:37:16.697578Z",
          "shell.execute_reply": "2026-01-06T18:37:16.696419Z",
          "shell.execute_reply.started": "2026-01-06T18:37:15.870642Z"
        },
        "id": "TxPj-_Y5gJ8U",
        "outputId": "0ccf0712-f596-4021-fce7-3a3f7991baa5",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/IMDB_Dataset.csv')\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJJ7E4ctgJ8W"
      },
      "source": [
        "### Declaring the english stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:16.699429Z",
          "iopub.status.busy": "2026-01-06T18:37:16.698944Z",
          "iopub.status.idle": "2026-01-06T18:37:16.705810Z",
          "shell.execute_reply": "2026-01-06T18:37:16.704551Z",
          "shell.execute_reply.started": "2026-01-06T18:37:16.699398Z"
        },
        "id": "xK-Q0nMcgJ8W",
        "outputId": "e4e13f1b-b512-4f41-b43a-4194135e4175",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "english_stops = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btSs3gGXgJ8X"
      },
      "source": [
        "### Load and Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:16.708298Z",
          "iopub.status.busy": "2026-01-06T18:37:16.707887Z",
          "iopub.status.idle": "2026-01-06T18:37:24.987674Z",
          "shell.execute_reply": "2026-01-06T18:37:24.986671Z",
          "shell.execute_reply.started": "2026-01-06T18:37:16.708267Z"
        },
        "id": "Ld1wRwragJ8Y",
        "outputId": "19ec4932-169f-4092-cf30-214ac7eae4a1",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews\n",
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "49995    [i, thought, movie, right, good, job, it, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [i, catholic, taught, parochial, elementary, s...\n",
            "49998    [i, going, disagree, previous, comment, side, ...\n",
            "49999    [no, one, expects, star, trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "49995    1\n",
            "49996    0\n",
            "49997    0\n",
            "49998    0\n",
            "49999    0\n",
            "Name: sentiment, Length: 50000, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7504667.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  y_data = y_data.replace('negative', 0)\n"
          ]
        }
      ],
      "source": [
        "def load_dataset():\n",
        "    data = pd.read_csv('/content/drive/MyDrive/IMDB_Dataset.csv')\n",
        "    x_data = data['review']       # Reviews/Input\n",
        "    y_data = data['sentiment']    # Sentiment/Output\n",
        "\n",
        "    # PRE-PROCESS REVIEW\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "\n",
        "    # ENCODE SENTIMENT -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMWqyy9sgJ8Z"
      },
      "source": [
        "### Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:24.989756Z",
          "iopub.status.busy": "2026-01-06T18:37:24.989359Z",
          "iopub.status.idle": "2026-01-06T18:37:25.013724Z",
          "shell.execute_reply": "2026-01-06T18:37:25.012695Z",
          "shell.execute_reply.started": "2026-01-06T18:37:24.989728Z"
        },
        "id": "f3rRqY0TgJ8Z",
        "outputId": "baf01ca4-960b-419d-c0ac-35ae8c59f4cf",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set\n",
            "47867    [i, agree, capital, city, dvd, i, watched, sho...\n",
            "8905     [cheap, manipulative, this, film, heart, it, a...\n",
            "14277    [i, surprised, film, well, hamptons, film, fes...\n",
            "4073     [though, series, ran, season, stayed, years, i...\n",
            "29863    [i, get, diehl, character, posed, microcosm, a...\n",
            "                               ...                        \n",
            "3180     [i, seen, hundreds, silent, movies, some, alwa...\n",
            "6715     [what, makes, best, picture, material, the, os...\n",
            "38047    [the, way, story, played, interaction, lead, c...\n",
            "14996    [and, since, days, clarissa, explains, it, all...\n",
            "36682    [one, biggest, hits, brown, harvard, exciting,...\n",
            "Name: review, Length: 40000, dtype: object \n",
            "\n",
            "43044    [like, earliest, films, movie, short, lasting,...\n",
            "27025    [no, one, going, mistake, the, squall, good, m...\n",
            "26560    [the, idea, making, miniseries, berlin, airlif...\n",
            "15168    [landscape, battle, opens, escaping, prisoners...\n",
            "21718    [todd, rohal, mad, genius, knuckleface, jones,...\n",
            "                               ...                        \n",
            "40600    [late, great, grade, z, drive, exploitation, f...\n",
            "37492    [when, converting, book, film, generally, good...\n",
            "29435    [i, finally, managed, sit, whole, episode, sho...\n",
            "29790    [i, really, enjoyed, one, although, ending, ma...\n",
            "5140     [at, first, movie, seemed, great, characters, ...\n",
            "Name: review, Length: 10000, dtype: object \n",
            "\n",
            "Test Set\n",
            "47867    1\n",
            "8905     0\n",
            "14277    0\n",
            "4073     1\n",
            "29863    0\n",
            "        ..\n",
            "3180     1\n",
            "6715     1\n",
            "38047    1\n",
            "14996    1\n",
            "36682    1\n",
            "Name: sentiment, Length: 40000, dtype: int64 \n",
            "\n",
            "43044    1\n",
            "27025    0\n",
            "26560    0\n",
            "15168    1\n",
            "21718    1\n",
            "        ..\n",
            "40600    1\n",
            "37492    0\n",
            "29435    0\n",
            "29790    1\n",
            "5140     0\n",
            "Name: sentiment, Length: 10000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
        "\n",
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC_1LNUzgJ8a"
      },
      "source": [
        "### Function for getting the maximum review length, by calculating the mean of all the reviews length (using <b>numpy.mean</b>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:25.016191Z",
          "iopub.status.busy": "2026-01-06T18:37:25.015034Z",
          "iopub.status.idle": "2026-01-06T18:37:25.023532Z",
          "shell.execute_reply": "2026-01-06T18:37:25.022292Z",
          "shell.execute_reply.started": "2026-01-06T18:37:25.016154Z"
        },
        "id": "GfkfTt3UgJ8a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXgVfRibgJ8b"
      },
      "source": [
        "### Tokenize and Pad/Truncate Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:25.025574Z",
          "iopub.status.busy": "2026-01-06T18:37:25.025188Z",
          "iopub.status.idle": "2026-01-06T18:37:31.782039Z",
          "shell.execute_reply": "2026-01-06T18:37:31.780399Z",
          "shell.execute_reply.started": "2026-01-06T18:37:25.025529Z"
        },
        "id": "UzYF2-xBgJ8b",
        "outputId": "42a6d895-f952-4ca0-a43a-09904fec9a81",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[   1  936 5367 ...  342   45 4801]\n",
            " [ 596 4726    8 ...    0    0    0]\n",
            " [   1  653    4 ...    0    0    0]\n",
            " ...\n",
            " [   2   26   13 ...    0    0    0]\n",
            " [  32  141  389 ...    0    0    0]\n",
            " [   5 1044 1807 ... 1771  320    7]] \n",
            "\n",
            "Encoded X Test\n",
            " [[   6 7997   34 ...    0    0    0]\n",
            " [ 249    5   80 ...   70  602 5893]\n",
            " [   2  228  137 ...   81 6294    0]\n",
            " ...\n",
            " [   1  331 1275 ...    0    0    0]\n",
            " [   1   14  415 ...  110 1789  824]\n",
            " [ 285   23    3 ...    0    0    0]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ],
      "source": [
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om3U3_qSgJ8c"
      },
      "source": [
        "### Build Architecture/Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:31.783883Z",
          "iopub.status.busy": "2026-01-06T18:37:31.783482Z",
          "iopub.status.idle": "2026-01-06T18:37:31.795680Z",
          "shell.execute_reply": "2026-01-06T18:37:31.794607Z",
          "shell.execute_reply.started": "2026-01-06T18:37:31.783851Z"
        },
        "id": "rD08rrqEgJ8c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def build_ensemble_model():\n",
        "    inputs = Input(shape=(max_length,))\n",
        "    embed = Embedding(total_words, 32)(inputs)\n",
        "\n",
        "    # Three branches\n",
        "    lstm = Dense(1, activation='sigmoid')(Dropout(0.2)(LSTM(64)(embed)))\n",
        "    cnn = Dense(1, activation='sigmoid')(Dropout(0.3)(GlobalMaxPooling1D()(Conv1D(32, 3, activation='relu')(embed))))\n",
        "    gru = Dense(1, activation='sigmoid')(Dropout(0.2)(GRU(64)(embed)))\n",
        "\n",
        "    # Combine them\n",
        "    output = Average()([lstm, cnn, gru])\n",
        "\n",
        "    model = Model(inputs, output)\n",
        "    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRfbTbnMgJ8d"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:31.799471Z",
          "iopub.status.busy": "2026-01-06T18:37:31.799102Z",
          "iopub.status.idle": "2026-01-06T18:37:31.822377Z",
          "shell.execute_reply": "2026-01-06T18:37:31.821278Z",
          "shell.execute_reply.started": "2026-01-06T18:37:31.799441Z"
        },
        "id": "TVf9PO60gJ8d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create model directory\n",
        "os.makedirs('/content/drive/MyDrive/models', exist_ok=True)\n",
        "\n",
        "# Save model\n",
        "model = build_ensemble_model()\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/models/Ensemble.keras', monitor='accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "earlyStopping = EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    patience=1,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:37:31.824061Z",
          "iopub.status.busy": "2026-01-06T18:37:31.823680Z",
          "iopub.status.idle": "2026-01-06T18:40:43.262699Z",
          "shell.execute_reply": "2026-01-06T18:40:43.261744Z",
          "shell.execute_reply.started": "2026-01-06T18:37:31.824002Z"
        },
        "id": "JOkTMjVegJ8e",
        "outputId": "5a924da5-71ea-4bff-decb-24aa508a033d",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6720 - loss: 0.6137\n",
            "Epoch 1: accuracy improved from -inf to 0.74539, saving model to /content/drive/MyDrive/models/Ensemble.keras\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 146ms/step - accuracy: 0.6721 - loss: 0.6136 - val_accuracy: 0.8087 - val_loss: 0.4667\n",
            "Epoch 2/100\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.8202 - loss: 0.4404\n",
            "Epoch 2: accuracy improved from 0.74539 to 0.81561, saving model to /content/drive/MyDrive/models/Ensemble.keras\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 148ms/step - accuracy: 0.8202 - loss: 0.4404 - val_accuracy: 0.8245 - val_loss: 0.4389\n",
            "Epoch 3/100\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8586 - loss: 0.3896\n",
            "Epoch 3: accuracy improved from 0.81561 to 0.86800, saving model to /content/drive/MyDrive/models/Ensemble.keras\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 148ms/step - accuracy: 0.8586 - loss: 0.3896 - val_accuracy: 0.8430 - val_loss: 0.4788\n",
            "Epoch 4/100\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.9105 - loss: 0.3997\n",
            "Epoch 4: accuracy improved from 0.86800 to 0.89931, saving model to /content/drive/MyDrive/models/Ensemble.keras\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 149ms/step - accuracy: 0.9105 - loss: 0.3997 - val_accuracy: 0.8450 - val_loss: 0.4171\n",
            "Epoch 5/100\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.9388 - loss: 0.3703\n",
            "Epoch 5: accuracy improved from 0.89931 to 0.92614, saving model to /content/drive/MyDrive/models/Ensemble.keras\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 147ms/step - accuracy: 0.9388 - loss: 0.3703 - val_accuracy: 0.8285 - val_loss: 0.4044\n",
            "Epoch 6/100\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.9323 - loss: 0.3134\n",
            "Epoch 6: accuracy improved from 0.92614 to 0.93714, saving model to /content/drive/MyDrive/models/Ensemble.keras\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 150ms/step - accuracy: 0.9323 - loss: 0.3134 - val_accuracy: 0.8413 - val_loss: 0.4927\n",
            "Epoch 7/100\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.9509 - loss: 0.3906\n",
            "Epoch 7: accuracy improved from 0.93714 to 0.93883, saving model to /content/drive/MyDrive/models/Ensemble.keras\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 150ms/step - accuracy: 0.9509 - loss: 0.3906 - val_accuracy: 0.7893 - val_loss: 0.5036\n",
            "Epoch 8/100\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9355 - loss: 0.2893\n",
            "Epoch 8: accuracy did not improve from 0.93883\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 145ms/step - accuracy: 0.9355 - loss: 0.2893 - val_accuracy: 0.8453 - val_loss: 0.4550\n",
            "Epoch 8: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f366803980>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.1, callbacks=[checkpoint, earlyStopping], verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMglvYE7gJ8e"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:40:43.264577Z",
          "iopub.status.busy": "2026-01-06T18:40:43.264200Z",
          "iopub.status.idle": "2026-01-06T18:40:58.534038Z",
          "shell.execute_reply": "2026-01-06T18:40:58.532948Z",
          "shell.execute_reply.started": "2026-01-06T18:40:43.264532Z"
        },
        "id": "vwqxietVgJ8f",
        "outputId": "1926dbcf-e8a3-4dfe-b75e-8a2b9b72a06e",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 84.03%\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(x_test, verbose=0)\n",
        "accuracy = np.mean((y_pred > 0.5).flatten() == y_test) * 100\n",
        "print(f\"\\nAccuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp4I5LQ0gJ8f"
      },
      "source": [
        "### Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T18:40:58.535724Z",
          "iopub.status.busy": "2026-01-06T18:40:58.535284Z",
          "iopub.status.idle": "2026-01-06T18:40:59.147161Z",
          "shell.execute_reply": "2026-01-06T18:40:59.146308Z",
          "shell.execute_reply.started": "2026-01-06T18:40:58.535684Z"
        },
        "id": "oT42Qfx2gJ8g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Ensemble_model = load_model('/content/drive/MyDrive/models/Ensemble.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pscdvKY2gJ8g"
      },
      "source": [
        "Receives a review as an input to be predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:40:59.149019Z",
          "iopub.status.busy": "2026-01-06T18:40:59.148647Z",
          "iopub.status.idle": "2026-01-06T18:41:37.570623Z",
          "shell.execute_reply": "2026-01-06T18:41:37.569537Z",
          "shell.execute_reply.started": "2026-01-06T18:40:59.148977Z"
        },
        "id": "iUH5qKTrgJ8g",
        "outputId": "8bab3ca5-4533-4445-a609-ffccb4b7b4ee",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie Review: good\n"
          ]
        }
      ],
      "source": [
        "review = str(input('Movie Review: '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV1j6M-EgJ8h"
      },
      "source": [
        "The input must be pre processed before it is passed to the model to be predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:41:37.572105Z",
          "iopub.status.busy": "2026-01-06T18:41:37.571776Z",
          "iopub.status.idle": "2026-01-06T18:41:37.579236Z",
          "shell.execute_reply": "2026-01-06T18:41:37.578168Z",
          "shell.execute_reply.started": "2026-01-06T18:41:37.572031Z"
        },
        "id": "ICGZRG_VgJ8h",
        "outputId": "536c60bf-c1f0-4178-e323-fad5f373f338",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned:  good\n",
            "Filtered:  ['good']\n"
          ]
        }
      ],
      "source": [
        "# Pre-process input\n",
        "regex = re.compile(r'[^a-zA-Z\\s]')\n",
        "review = regex.sub('', review)\n",
        "print('Cleaned: ', review)\n",
        "\n",
        "words = review.split(' ')\n",
        "filtered = [w for w in words if w not in english_stops]\n",
        "filtered = ' '.join(filtered)\n",
        "filtered = [filtered.lower()]\n",
        "\n",
        "print('Filtered: ', filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmGsKOu4gJ8h"
      },
      "source": [
        "We need to tokenize and encode the words. I use the tokenizer which was previously declared because we want to encode the words based on words that are known by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:41:37.580746Z",
          "iopub.status.busy": "2026-01-06T18:41:37.580386Z",
          "iopub.status.idle": "2026-01-06T18:41:37.600485Z",
          "shell.execute_reply": "2026-01-06T18:41:37.599322Z",
          "shell.execute_reply.started": "2026-01-06T18:41:37.580697Z"
        },
        "id": "hjYMQzipgJ8i",
        "outputId": "c157c1f2-fb62-44f9-9656-8d24a1c0ba45",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "tokenize_words = token.texts_to_sequences(filtered)\n",
        "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "print(tokenize_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDNme8bOgJ8i"
      },
      "source": [
        "This is the result of the prediction which shows the **confidence score** of the review statement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:41:37.602042Z",
          "iopub.status.busy": "2026-01-06T18:41:37.601565Z",
          "iopub.status.idle": "2026-01-06T18:41:45.951910Z",
          "shell.execute_reply": "2026-01-06T18:41:45.950830Z",
          "shell.execute_reply.started": "2026-01-06T18:41:37.602002Z"
        },
        "id": "tsj_fAf-gJ8i",
        "outputId": "ce8af340-b264-402f-fb3b-7f0d5bcfa9ef",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "0.81275547\n"
          ]
        }
      ],
      "source": [
        "# Get predictions from model\n",
        "result = model.predict(tokenize_words)[0][0]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AqQvWeOgJ8j"
      },
      "source": [
        "Check whether the review is negative or postive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-06T18:41:45.953785Z",
          "iopub.status.busy": "2026-01-06T18:41:45.953418Z",
          "iopub.status.idle": "2026-01-06T18:41:45.959715Z",
          "shell.execute_reply": "2026-01-06T18:41:45.958608Z",
          "shell.execute_reply.started": "2026-01-06T18:41:45.953757Z"
        },
        "id": "WLkRb1yTgJ8j",
        "outputId": "841b6fcd-2644-4503-eace-e60aaa2c4395",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "if result >= 0.7:\n",
        "    print('positive')\n",
        "else:\n",
        "    print('negative')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 134715,
          "sourceId": 320111,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31234,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}